"""Tests for CEFR data file validation.

Validates JSON structure and schema of vocabulary and grammar files
as they are generated by other agents.
"""

import json
from pathlib import Path

import pytest

CEFR_DATA_DIR = Path(__file__).parent.parent / "src" / "ankicli" / "data" / "cefr"
VOCAB_DIR = CEFR_DATA_DIR / "vocabulary"
GRAMMAR_DIR = CEFR_DATA_DIR / "grammar"

# Required fields for vocabulary entries
VOCAB_REQUIRED_FIELDS = {"word", "english", "pos", "category"}
VOCAB_VALID_POS = {"noun", "verb", "adjective", "adverb", "preposition",
                   "conjunction", "pronoun", "determiner", "interjection",
                   "phrase", "expression", "numeral", "article"}

# Required fields for grammar entries
GRAMMAR_REQUIRED_FIELDS = {"id", "concept", "category", "description"}


class TestMetadata:
    """Tests for metadata.json."""

    def test_metadata_exists(self):
        assert (CEFR_DATA_DIR / "metadata.json").exists()

    def test_metadata_valid_json(self):
        with open(CEFR_DATA_DIR / "metadata.json") as f:
            data = json.load(f)
        assert isinstance(data, dict)

    def test_metadata_has_required_fields(self):
        with open(CEFR_DATA_DIR / "metadata.json") as f:
            data = json.load(f)
        assert "version" in data
        assert "language" in data
        assert "levels" in data
        assert data["language"] == "es"

    def test_metadata_lists_all_levels(self):
        with open(CEFR_DATA_DIR / "metadata.json") as f:
            data = json.load(f)
        expected = {"A1", "A2", "B1", "B2", "C1", "C2"}
        assert set(data["levels"]) == expected


class TestThemes:
    """Tests for themes.json."""

    def test_themes_exists(self):
        assert (CEFR_DATA_DIR / "themes.json").exists()

    def test_themes_valid_json(self):
        with open(CEFR_DATA_DIR / "themes.json") as f:
            data = json.load(f)
        assert isinstance(data, dict)
        assert "themes" in data

    def test_themes_have_required_fields(self):
        with open(CEFR_DATA_DIR / "themes.json") as f:
            data = json.load(f)
        for theme in data["themes"]:
            assert "id" in theme, f"Theme missing 'id': {theme}"
            assert "name" in theme, f"Theme missing 'name': {theme}"
            assert "description" in theme, f"Theme missing 'description': {theme}"

    def test_theme_ids_unique(self):
        with open(CEFR_DATA_DIR / "themes.json") as f:
            data = json.load(f)
        ids = [t["id"] for t in data["themes"]]
        assert len(ids) == len(set(ids)), "Duplicate theme IDs found"


def _get_vocab_files():
    """Get all vocabulary JSON files that exist."""
    if not VOCAB_DIR.exists():
        return []
    return sorted(VOCAB_DIR.glob("*.json"))


def _get_grammar_files():
    """Get all grammar JSON files that exist."""
    if not GRAMMAR_DIR.exists():
        return []
    return sorted(GRAMMAR_DIR.glob("*.json"))


class TestVocabularyFiles:
    """Tests for vocabulary JSON files."""

    def test_vocab_dir_exists(self):
        assert VOCAB_DIR.exists()

    @pytest.mark.parametrize("vocab_file", _get_vocab_files(),
                             ids=lambda p: p.stem)
    def test_valid_json(self, vocab_file):
        with open(vocab_file) as f:
            data = json.load(f)
        assert isinstance(data, list), f"{vocab_file.name} should contain a JSON array"
        assert len(data) > 0, f"{vocab_file.name} is empty"

    @pytest.mark.parametrize("vocab_file", _get_vocab_files(),
                             ids=lambda p: p.stem)
    def test_entries_have_required_fields(self, vocab_file):
        with open(vocab_file) as f:
            data = json.load(f)
        for i, entry in enumerate(data):
            for field in VOCAB_REQUIRED_FIELDS:
                assert field in entry, (
                    f"{vocab_file.name}[{i}]: missing '{field}' in entry: "
                    f"{entry.get('word', 'unknown')}"
                )

    @pytest.mark.parametrize("vocab_file", _get_vocab_files(),
                             ids=lambda p: p.stem)
    def test_entries_have_valid_pos(self, vocab_file):
        with open(vocab_file) as f:
            data = json.load(f)
        for i, entry in enumerate(data):
            pos = entry.get("pos", "")
            assert pos in VOCAB_VALID_POS, (
                f"{vocab_file.name}[{i}]: invalid pos '{pos}' for "
                f"'{entry.get('word', 'unknown')}'. Valid: {VOCAB_VALID_POS}"
            )

    @pytest.mark.parametrize("vocab_file", _get_vocab_files(),
                             ids=lambda p: p.stem)
    def test_words_are_nonempty_strings(self, vocab_file):
        with open(vocab_file) as f:
            data = json.load(f)
        for i, entry in enumerate(data):
            assert isinstance(entry["word"], str) and len(entry["word"]) > 0, (
                f"{vocab_file.name}[{i}]: 'word' must be a non-empty string"
            )
            assert isinstance(entry["english"], str) and len(entry["english"]) > 0, (
                f"{vocab_file.name}[{i}]: 'english' must be a non-empty string"
            )

    @pytest.mark.parametrize("vocab_file", _get_vocab_files(),
                             ids=lambda p: p.stem)
    def test_no_duplicate_words(self, vocab_file):
        with open(vocab_file) as f:
            data = json.load(f)
        words = [e["word"] for e in data]
        duplicates = [w for w in words if words.count(w) > 1]
        unique_duplicates = set(duplicates)
        assert len(unique_duplicates) == 0, (
            f"{vocab_file.name}: duplicate words found: {unique_duplicates}"
        )

    @pytest.mark.parametrize("vocab_file", _get_vocab_files(),
                             ids=lambda p: p.stem)
    def test_categories_match_themes(self, vocab_file):
        with open(CEFR_DATA_DIR / "themes.json") as f:
            themes = json.load(f)
        valid_categories = {t["id"] for t in themes["themes"]}

        with open(vocab_file) as f:
            data = json.load(f)
        for i, entry in enumerate(data):
            cat = entry.get("category", "")
            assert cat in valid_categories, (
                f"{vocab_file.name}[{i}]: invalid category '{cat}' for "
                f"'{entry['word']}'. Valid: {valid_categories}"
            )


class TestGrammarFiles:
    """Tests for grammar JSON files."""

    def test_grammar_dir_exists(self):
        assert GRAMMAR_DIR.exists()

    @pytest.mark.parametrize("grammar_file", _get_grammar_files(),
                             ids=lambda p: p.stem)
    def test_valid_json(self, grammar_file):
        with open(grammar_file) as f:
            data = json.load(f)
        assert isinstance(data, list), f"{grammar_file.name} should contain a JSON array"
        assert len(data) > 0, f"{grammar_file.name} is empty"

    @pytest.mark.parametrize("grammar_file", _get_grammar_files(),
                             ids=lambda p: p.stem)
    def test_entries_have_required_fields(self, grammar_file):
        with open(grammar_file) as f:
            data = json.load(f)
        for i, entry in enumerate(data):
            for field in GRAMMAR_REQUIRED_FIELDS:
                assert field in entry, (
                    f"{grammar_file.name}[{i}]: missing '{field}' in entry: "
                    f"{entry.get('concept', 'unknown')}"
                )

    @pytest.mark.parametrize("grammar_file", _get_grammar_files(),
                             ids=lambda p: p.stem)
    def test_ids_are_unique(self, grammar_file):
        with open(grammar_file) as f:
            data = json.load(f)
        ids = [e["id"] for e in data]
        duplicates = set(i for i in ids if ids.count(i) > 1)
        assert len(duplicates) == 0, (
            f"{grammar_file.name}: duplicate IDs: {duplicates}"
        )

    @pytest.mark.parametrize("grammar_file", _get_grammar_files(),
                             ids=lambda p: p.stem)
    def test_has_practice_patterns(self, grammar_file):
        with open(grammar_file) as f:
            data = json.load(f)
        for i, entry in enumerate(data):
            if "practice_patterns" in entry:
                assert isinstance(entry["practice_patterns"], list), (
                    f"{grammar_file.name}[{i}]: practice_patterns must be a list"
                )
                assert len(entry["practice_patterns"]) > 0, (
                    f"{grammar_file.name}[{i}]: practice_patterns should not be empty"
                )
